## 12. 모델 성능 최적화 및 배포

#### 🔍 개념 정리
- 모델 최적화 목표
  1. 추론 속도 향상
  2. 메모리 사용량 감소
  3. 에너지 효율성 증가
  4. 정확도 유지

- 병목 지점
  - 과도한 메모리 사용 계층
  - 연산량이 많은 합성곱 또는 행렬 곱셈 계층
  - CPU-GPU 간 데이터 전송
  - 비효율적인 데이터 로딩 프로세스

- 양자화: 모델의 파라미터를 낮은 비트 정밀도로 표현해 모델 크기를 줄이고 연산 속도를 높이는 기법
  - 딥러닝 모델은 보통 가중치, 활성값을 float32로 저장함 -> 메모리를 많이 먹고 연산이 느림
  - 위 문제를 해결하기 위해 숫자를 더 작은 정수로 바꿔주는 양자화 진행
  1. 동적 양자화: 가중치를 정적으로 양자화하고, 활성화 함수의 출력값은 실행 시간에 동적으로 양자화함
     - 가중치는 미리 int8로 바꾸고 activation은 실행할 때마다 동적으로 범위 계산해서 양자화
  2. 정적 양자화: 가중치와 활성화 함수의 출력값을 모두 사전에 양자화함
     - 보정 과정이 필요
     - 대표적인 입력 데이터를 통해 활성화 함수의 출력값 분포를 파악함

- 가지치기: 모델에서 중요도가 낮은 파라미터나 뉴런을 제거하는 기법, 모델 크기를 줄이고 연산량 감소시킴
  - 비구조적 가지치기: 개별 가중치를제거해 희소 행렬을 만듦
  - 구조적 가지치기: 뉴런, 채널, 필터와 같은 구조적 단위를 제거함
  - 점진적 가지치기: 학습-가지치기-재학습 사이클을 반복해 정확도 손실을 최소화하면서 모델을 경량화함

- 지식 증류: 크고 복잡한 교사 모델의 지식을 작은 학생 모델로 전달하는 기법
  - student는 teacher를 모방하도록 학습함

- ONNX: 다양한 딥러닝 프레임워크 간 모델 교환을 위한 표준 포맷
  - 학습은 파이토치에서 했는데 배포는 C++환경에서 하고 싶을 때
- TorchScipt: 파이토치 모델을 최적화함
  - 파이토치 모델을 파이토치 없이 실행 가능하게 만드는 기술 
