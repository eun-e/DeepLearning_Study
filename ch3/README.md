<img width="278" height="124" alt="image" src="https://github.com/user-attachments/assets/2f947697-41b0-4e54-8f6f-74c16f9214b4" />## Chapter 3-1. 신경망의 개요

#### 🔍 인공뉴런
- 여러 입력값을 가중치와 함께 조합하여 연산을 수행하고, 특정 활성화 함수를 적용해 최종 출력을 생산한다
- 가중치 매개 변수와 편향값을 포함하며, 학습 과정을 통해 조정된다 <br>
  → 가중치는 입력값의 중요도를 결정하며, 학습 과정에서 최적의 값을 찾는다 <br>
  → 편향은 활성화 함수를 거치기 전에 일정한 조정을 수행하여 뉴런의 활성화 여부를 더 정밀하게 조정한다
- 활성화 함수: ReLU, Sigmoid, Tanh 등이 있으며 선형 연산을 비선형 변환한다

#### 🔍 신경망의 종류
1. MLP: 여러 개의 은닉층으로 구성된 완전 연결 신경망 → 공간적, 시간적 구조를 학습하는 능력이 부족해 이미지나 시계열 데이터 처리에는 적합하지 않음
2. CNN: 이미지 데이터와 같은 2차원의 구조화된 데이터에 적합도록 설계된 신경망 → convolution과 pooling 연산을 통해 특징을 추출함
3. RNN: 시계열 데이터를 다루는 데 특화된 신경망 → 이전 상태의 정보를 저장해 시간에 따라 변하는 데이터를 효과적으로 처리함

#### 🔍 신경망의 응용
1. CV: 이미지 및 영상 데이터를 처리해 의미 있는 정보를 추출하는 분야 - CNN 사용
2. NLP: 인간의 언어를 기계가 이해하고 처리하는 기술 - RNN, LSTM, Transformer 사용

<br>

## Chapter 3-2. 기본신경망 구조의 이해

#### 🔍 단일 퍼셉트론의 기본 모델
<img width="278" height="124" alt="image" src="https://github.com/user-attachments/assets/16dc5dbc-7a2e-4f26-8ae3-07ba0f6bb599" />
- 가중치(w): 초기에는 랜덤 값으로 설정되며, 경사 하강법과 같은 알고리즘을 통해 학습이 진행될수록 업데이트됨 → 과적합되는 경우 가중치 정규화 활용
- 편향: 뉴런이 일정한 출력을 생성할 수 있도록 도움 if 편향이 0인 경우, 활성화 함수가 원점을 중심으로 작동하게 되어 학습 제한됨

#### 🔍 다층 신경망 구조
하나 이상의 은닉층을 포함하며 비선형 문제(XOR)를 해결할 수 있음
- 정규화 기법: L1 및 L2 정규화, Dropout, Batch Normalization
층 깊이를증가하면 신경망의 표현력이 강화되지만, 기울기 소실 문제가 발생 가능함 → Residual Connection 기법 활용


