##  10-1. 오디오 신호 처리 기초

#### 🔍 개념 정리
- 샘플링: 연속적인 아날로그 신호를 일정한 시간 간격으로 측정해 이산적인 값으로 만드는 과정
  - 샘플링 레이트: 1초당 샘플 수, 단위는 Hz (사람이 들을 수 잇는 주파수: 약 20~20kHz)
  - 나이키스트 정리: 원본 신호 최대 주파수의 2배 이상으로 샘플링 필요
  - 샘플링이 클수록 시간적으로 더 부드러운 소리, 고주파 표현에 유리함
- 양자화: 각 샘플의 진폭을 유한한 수치로 표현하는 과정
  - 양자화 비트: 각 샘플의 진폭을 몇 비트로 표현할지 결정 (16 or 24비트 사용)
- 디지털 오디오 변환 과정
  1. 아날로그 신호: 연속적인 시간과 진폭을 가진 원본 신호, 자연계에서 발생하는 실제 소리
  2. 샘플링: 일정한 시간 간격으로 신호 값
  3. 양자화: 연속적인 진폭값을 유한한 개수의 이산적 값으로 변환, 양자화 비트 수가 클수록 정밀한 표현 가능
- 오디오 신호
  - 진폭: 신호의 크기로 소리의 세기를 나타냄(볼륨)
  - 주파수: 1초당 진동 횟수로 소리의 높낮이를 결정함(Hz)
  - 위상: 신호의 시작점에 대한 상대적인 위치로 소리의 공간적 특성에 영향을 줌
  - 음색: 같은 음높이와 세기를 가진 소리를 구별하게 하는 특성으로 배음 구조에 의해 결정됨
- PCM: 아날로그 신호를 디지털로 변환하는 가장 기본적인 방식
- WAV: PCM 데이터를 저장하는 표준 파일 형식(scipy.io.wavfile/librosa library in python)
   - RIFF 헤더: 파일의 시작을 나타내며 파일 크기와 포맷 정보를 포함함
   - fmt 청크: 포맷 정보를 포함하며 샘플링 레이트, 비트 깊이, 채널 수 등을 명시함
   - data 청크: 실제 오디오 데이터를 포함함
     
````python
import librosa
import numpy as np
from IPython.display import Audio, display # 오디오를 불러와 화면에 출력
````

- 샘플링 레이트 변환: 오디오 데이터를 수집할 때 샘플링 레이트가 서로 다른 경우
  1. 오디오를 tensor로 변환: torch.tensor(audio).unsqueeze(0).float()
     - (N,) 1차원 형태의 audio.shape을 (1,N)로 변경함 -> 채널 차원 추가(channel=1) <br>
       ⎿ batch가 아니라 channel을 추가하는 것! batch는 DataLoader에 붙거나 모델 입력에 맞춰 추가로 unsqueeze함
     - 원래 int 였던 자료를 float으로 자료형 바꾸기 - Pytorch 연산하기 위해서
  2. torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)
     - 점 간격을 재조정해서 새 시간축에 맞게 값을 재계산함
     - 다운샘플링은 aliasing을 유발할 수 있음

- 노이즈 제거
  1. 저역 통과 필터: 낮은 주파수만 통과, 목소리만 남기고 잡음 제거 등
     - aliasing을 방지하기 위해 다운 샘플링 전에 저역 통과 필터를 적용함
  2. 고역 통과 필터: 저주파 노이즈 제거, 마이크 바람 소리 제거 등
  3. 대역 통과 필터 특정 주파수만 통과 가능하게 함

- 정규화: 오디오 신호의 볼륨 레벨을 일정하게 맞추기 위
  1. 피크 정규화: 가장 큰 피크가 목표값에 오도록 전체를 스케일링함
  2. RMS 정규화: 신호의 평균적인 크기를 나타내는 값이 목표 값에 오도록 스케일링함


      
#### ❓추가 정리 사항
- 샘플링 레이트 변환 vs 정규화
  - 정규화는 값의 진폭(범위)을 맞추는 것
  - 샘플링 레이트는 1초에 몇개로 쪼개서 표현했냐를 나타내는 것<br>
    ⎿ 오디오 텐서의 shape 예시: 단일 오디오-(N,)/(1,N) vs 배치로 묶이면 (batch, channel, time)<br>
    ⎿ 샘플링 레이트가 shape을 결정하는 건 아니고 같은 길이일 때 time 축 길이를 결정함<br>
    ⎿ 샘플링 레이트가 다르면 같은 1초라도 time 길이와 주파수 표현 범위가 달라져서 통일함
- 보통 샘플링 레이트 변환은 다운샘플링 but 정보 손실 발생 가능
````text
WHY? 사람 음성 정보는 대부분 8kHz 이하여서 나이키스트 정리에 의해 16kHz 샘플링이면 충분
     음악이나 영상은 보통 40kHz가 넘기 때문에 다운샘플링 필요
````
- shape 정리
```text
▪️Channel이란? 하나의 데이터 안에 존재하는 병렬 신호 개수
   모노면 channel=1, 스테레오면 channel=2
▪️Batch란? 모델에 한 번에 넣는 데이터 개수

-> (batch, channel, time)=(32,1,16000)이면 32개 오디오, 각 오디오가 모노, 각 오디오가 16000 샘플이라는 뜻
````
- Aliasing: 고주파가 저주파로 잘못 보이는 현상 <br>
  ⎿ 우리는 빠르게 진동하는 걸 자주 보지 않으면 진동을 구별하지 못함 <br>
      ex. 분쇄기가 너무 빠르게 회전하면 멈춰있는 것처럼 보임 <br>
  ⎿ 최소 진동당 2번을 봐야함 -> 나이키스트 정리
  








